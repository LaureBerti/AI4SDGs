# üåç SDG#15. Acoustic Biodiversity Assessment with VAE

> An evolving list of resources, tools, datasets, papers, and communities focused on **Variational Autoencoders** for ecoacoustic monitoring and biodiversity assessment.

> Feel free to update and contribute !

---

## Table of Contents

- [Introduction](#introduction)
- [Scientific Papers](#scientific-papers)
- [Datasets and Benchmarks](#datasets-and-benchmarks)
- [Libraries and Tools](#libraries-and-tools)
- [Use Cases](#use-cases)
- [Courses and Tutorials](#courses-and-tutorials)
- [Books](#books)
- [Communities and Conferences](#communities-and-conferences)
- [Conclusion](#conclusion)

---

## Introduction

Biodiversity is increasingly threatened by climate change, habitat loss, and human activity. Acoustic monitoring offers a scalable, non-invasive way to assess ecological health by capturing the rich soundscapes of natural environments. Variational Autoencoders (VAEs) provide a powerful, unsupervised framework to extract latent structure from large-scale ecoacoustic data. This page aggregates relevant resources‚Äîpapers, datasets, tools, and communities‚Äîat the intersection of bioacoustics and generative machine learning.

---

## Scientific Papers

- Towsey, M., et al. (2014). [*Visualization of Long-duration Acoustic Recordings of the Environment*](https://www.sciencedirect.com/science/article/pii/S1877050914002403)
- Gibb, R., , et al.  (2019). [*Emerging opportunities and challenges for passive acoustics in ecological assessment and monitoring*](https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/2041-210X.13101)
- Stowell, D., et al. (2018). [*Automatic acoustic detection of birds through deep learning: The first Bird Audio Detection challenge*](https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/2041-210x.13103)
- Purwins, H., et al. (2019). [*Deep Learning for Audio Signal Processing*](https://ieeexplore.ieee.org/document/8678825)
- Kahl, S., et al. (2021). [*BirdNET: A deep learning solution for avian diversity monitoring*](https://www.sciencedirect.com/science/article/pii/S1574954121000273)
- Hershey, S., Chaudhuri, S., Ellis, D. P., et al. (2017). [*CNN architectures for large-scale audio classification*](https://arxiv.org/abs/1609.09430)
- Kong, Q., Cao, Y., Iqbal, T., Wang, Y., Wang, W., & Plumbley, M. D. (2020). [*PANNs: Large-Scale Pretrained Audio Neural Networks for Audio Pattern Recognition*](https://arxiv.org/abs/1912.10211)
- Guerrero M.J., et al., (2023). [*Acoustic animal identification using unsupervised learning*](https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.14103) 
- Fiorio, L.V., et al. (2022). [*Unsupervised Variational Acoustic Clustering*](Unsupervised Variational Acoustic Clustering)
- Salamon, J., Bello, J. P. (2017). [*Deep convolutional neural networks and data augmentation for environmental sound classification*](https://ieeexplore.ieee.org/document/7829341)
- Lostanlen, V., et al. (2019). [*Robust sound event detection in bioacoustic sensor networks*](https://arxiv.org/abs/1905.08352)
- Alexander, C. et al., (2025). [*Automated note annotation after bioacoustic classification: Unsupervised clustering of extracted acoustic features improves detection of a cryptic owl*](https://www.sciencedirect.com/science/article/pii/S1574954125002316)
- Rauch, L. et al., (2025) [*Can Masked Autoencoders Also Listen to Birds?*](https://arxiv.org/html/2504.12880v1)

---

## Datasets and Benchmarks

- [**ESC: Dataset for Environmental Sound Classification**](https://github.com/karolpiczak/ESC-50) 
- [**DCASE Challenge**](https://dcase.community/)
- [**Urban Sound Monitoring SONYC-UST-v2**](https://arxiv.org/abs/2009.05188)
- [**SoundNet**](https://github.com/cvondrick/soundnet)
- [**Rainforest Connection (RFCx)**](https://www.rfcx.org/)
- [**BirdCLEF**](https://www.imageclef.org/BirdCLEF2025)
- [**QUT Ecoacoustics**](https://research.qut.edu.au/ecoacoustics/)
- [**UrbanSound8K**](https://urbansounddataset.weebly.com/urbansound8k.html)
- [**Arbimon Platform**](https://www.arbimon.org)

---

## Libraries and Tools

- [Librosa](https://librosa.org/)
- [OpenSoundscape](https://github.com/kitzeslab/opensoundscape)
- [scikit-maad](https://github.com/scikit-maad/scikit-maad)
- [PANNs](https://github.com/qiuqiangkong/audioset_tagging_cnn)
- [PyTorch-VAE](https://github.com/AntixK/PyTorch-VAE)

---

## Use Cases

- [Nature Sound Map](https://www.naturesoundmap.com/)
- [Arbimon Monitoring Platform](https://www.arbimon.org/)
- [WWF Bioacoustic Monitoring](https://www.wwf.org.uk/project/conservationtechnology/acoustic-monitoring)
- [Rainforest Connection Projects](https://www.rfcx.org/)
- [Soundscapes to Landscapes (S2L)](https://storymaps.arcgis.com/stories/402443b576c146f7b2e5fd8c008376a6)
- [Ocean Data](https://portal.aodn.org.au/search?uuid=8edf509b-1481-48fd-b9c5-b95b42247f82)
---

## Tutorials and Courses

- [Coursera: Audio Signal Processing for ML](https://www.coursera.org/learn/audio-signal-processing)
- [Medium: Deep Learning for Environmental Sounds](https://medium.com/search?q=environmental+sound)
- [VAE Concepts Explained ‚Äì Towards Data Science](https://towardsdatascience.com/intuitively-understanding-variational-autoencoders-1bfe67eb5daf)
- [Variational Autoencoder Tutorial (CodeAcademy)](https://www.codecademy.com/article/variational-autoencoder-tutorial-vaes-explained)


---

## Books

- [*Ecoacoustics: The Ecological Role of Sounds*](https://onlinelibrary.wiley.com/doi/book/10.1002/9781119230724) ‚Äì Farina & Gage (Springer)
- [*Deep Learning for the Life Sciences*](https://www.oreilly.com/library/view/deep-learning-for/9781492039822/) ‚Äì Bharath Ramsundar, Peter Eastman, Pat Walters, Vijay Pande (O‚ÄôReilly)
- [*Bioacoustics: A Comparative Approach*](https://www.amazon.fr/Bioacoustics-Comparative-Approach-Brian-Lewis/dp/0124465501) ‚Äì Lewis (Academic Press)

---

## Communities and Conferences

- [Acoustic Society of America](https://acousticalsociety.org/)
- [IQOE Bioacoustics Working Group & Observing Systems](https://www.iqoe.org/systems)
- [IEEE ICASSP](https://ieeeicassp.org/)
- [DCASE Community](https://dcase.community/)
---

## Conclusion

Acoustic biodiversity assessment is not only a technological challenge, but a mission-critical frontier in preserving global ecosystems. VAEs offer a scalable, unsupervised toolset for mapping complex acoustic environments into interpretable, generative latent spaces. Looking ahead, future research will likely explore:

- üéØ Self-supervised acoustic embeddings using contrastive learning
- ü§ñ Hybrid generative architectures (e.g., VAE-GANs)
- üåé Transferable ecoacoustic models across biomes
- ‚è± Real-time monitoring and edge deployment
- üß¨ Integrating acoustic and non-acoustic sensor modalities

---

**Want to contribute?** Feel free to open an issue or submit a pull request! üéØ

